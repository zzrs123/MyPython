# 说明

虽然以前会用一点python，但主要是来做拿到数据后的分析以及其他方面的事情，爬虫和词云偏偏就是没写过。

因此这两天尝试了一下。断断续续经历了

- 词云
- 蒙版词云
- 爬虫
- 爬指定网页
- 爬完再画词云

这个过程

因此，我的作业项目中也是这五个方面。

## 文件夹 spider-learn

参考网上的例程，爬取了豆瓣前100的高分电影，输出到json里，利用正则表达式处理数据，并命名为格式相对统一的样式。

blog是另一个爬虫程序的结果，但是源程序已经不在了。

## 文件夹 worldcloud-learn

主要参考同济子豪兄的github教程：https://github.com/TommyZihao/zihaopython。

分两步走，先出词云worldcloud_test1.py，再加上模板定制词云worldcloud_test2.py。

蒙版图片为download.png。词云图片分别为：wyy.jpg，wyy_pic.jpg。

## 文件夹 spider-do

主要是用爬虫爬取我想要的歌词，输出到文件。

实现的是从http://music.163.com/api/song/lyric?1949119429爬取歌曲《记念》的歌词，test1是输出到终端，test2是输出到jinian.txt。

## 文件夹 zhomework3

这个文件夹是我的作业。

主要是就是spider-do和worldcloud-learn两个文件夹的融合。

这一步很简单。

输出就是jinian_pic.jpg和jinian_pics.jpg。